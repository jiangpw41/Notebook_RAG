<!-- JPW的Markdown笔记模板 v1, 其中的href需要视情更改上级目录href="../../format.css -->
<link rel="stylesheet" type="text/css" href="../../format.css">


<h1>RAG系列：RAG系统性能评估</h1>

💡 主要分为对检索其和生成器的评估，此外还有系统效率评估。

# 1. 检索器性能评估
一些基于混淆矩阵Confusion Matrix的评估：

- **准确率（Precision）**：即检索到的文档中，有多少是与当前任务或者问题真正相关的。如果准确率高，说明检索阶段有效地过滤掉了不相关的文档，使得生成模型能够更准确地基于相关文档进行生成。$Precision = (其中实际相关的文档数)/(检索返回的文档总数)$

- **召回率（Recall）**：即与当前任务或者问题真正相关的文档中，有多少被检索到。高召回率意味着检索部分能够找到尽可能多的相关文档，从而为生成部分提供更多的信息。然而，召回率过高可能会导致不相关的文档也被检索到，影响生成质量。$Recall = (检索到的相关文档数) / (总相关文档数)$

- **F1 分数（F1-Score）**：F1 分数是准确率和召回率的调和平均数，通常作为一个综合指标来平衡二者。它可以帮助你在确保一定召回率的同时，避免过多的错误（不相关文档）被检索。可以通过调整检索的阈值、调整检索模型的超参数、或使用更精确的检索方法（例如基于语义的检索）来优化这两个指标的平衡。
$F1 = 2 * (Precision * Recall) / (Precision + Recall)$

- **其他指标**：
    - **平均精度均值（Mean Average Precision, MAP）：**
    对多个查询的平均精度取平均，适用于多查询场景，评估整体检索性能
    - **归一化折损累计增益（Normalized Discounted Cumulative Gain, NDCG）：**
    考虑文档排序的相关性评分。评估排序质量，适用于分级相关性。

# 2. 生成器性能评估
用于评估生成文本的质量，特别是与参考文本的相似度。 

## 2.1 BLEU
BLEU（Bilingual Evaluation Understudy双语评价替代）：n-gram精确率几何平均乘以惩罚因子（生成中与参考一致的）